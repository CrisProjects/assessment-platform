#!/usr/bin/env python3
"""
Script para probar el flujo completo de evaluaci√≥n despu√©s de la correcci√≥n
"""
import requests
import json

BASE_URL = "https://assessment-platform-1nuo.onrender.com"

def test_complete_flow():
    """Prueba completa del flujo de evaluaci√≥n"""
    session = requests.Session()
    
    print("üîÑ Iniciando prueba completa del flujo de evaluaci√≥n...")
    
    # 1. Verificar que la aplicaci√≥n est√© funcionando
    print("\n1. Verificando estado de la aplicaci√≥n...")
    health_response = session.get(f"{BASE_URL}/api/health")
    if health_response.status_code == 200:
        print("‚úÖ Aplicaci√≥n funcionando correctamente")
        print(f"   Estado: {health_response.json()}")
    else:
        print(f"‚ùå Error en aplicaci√≥n: {health_response.status_code}")
        return False
    
    # 2. Hacer login
    print("\n2. Haciendo login como admin...")
    login_data = {"username": "admin", "password": "admin123"}
    login_response = session.post(f"{BASE_URL}/api/login", json=login_data)
    
    if login_response.status_code == 200:
        print("‚úÖ Login exitoso")
        print(f"   Usuario: {login_response.json()['user']['username']}")
    else:
        print(f"‚ùå Error en login: {login_response.status_code}")
        return False
    
    # 3. Obtener preguntas de evaluaci√≥n
    print("\n3. Obteniendo preguntas de evaluaci√≥n...")
    questions_response = session.get(f"{BASE_URL}/api/questions")
    
    if questions_response.status_code == 200:
        questions_data = questions_response.json()
        questions = questions_data['questions']
        print(f"‚úÖ Preguntas obtenidas exitosamente")
        print(f"   Cantidad de preguntas: {len(questions)}")
        print(f"   Primera pregunta: {questions[0]['content'][:50]}...")
    else:
        print(f"‚ùå Error obteniendo preguntas: {questions_response.status_code}")
        print(f"   Respuesta: {questions_response.text}")
        return False
    
    # 4. Simular respuestas a la evaluaci√≥n
    print("\n4. Simulando respuestas a la evaluaci√≥n...")
    responses = []
    for i, question in enumerate(questions):
        # Simular respuesta (siempre la segunda opci√≥n para consistencia)
        responses.append({
            "question_id": question['id'],
            "selected_option": 1,  # √≠ndice de la segunda opci√≥n (m√°s asertiva)
            "option_text": question['options'][1]
        })
    
    assessment_data = {
        "assessment_id": 1,  # ID de la evaluaci√≥n de asertividad
        "responses": responses
    }
    
    save_response = session.post(f"{BASE_URL}/api/save_assessment", json=assessment_data)
    
    if save_response.status_code == 200:
        result = save_response.json()
        print("‚úÖ Evaluaci√≥n guardada exitosamente")
        print(f"   Puntuaci√≥n: {result.get('score', 'N/A')}")
        print(f"   Nivel de asertividad: {result.get('assertiveness_level', 'N/A')}")
    else:
        print(f"‚ùå Error guardando evaluaci√≥n: {save_response.status_code}")
        print(f"   Respuesta: {save_response.text}")
        return False
    
    print("\nüéâ ¬°FLUJO COMPLETO EXITOSO!")
    print("   El bot√≥n 'Iniciar Evaluaci√≥n' ahora deber√≠a funcionar correctamente.")
    return True

if __name__ == "__main__":
    success = test_complete_flow()
    if success:
        print("\n‚úÖ EVALUACI√ìN COMPLETADA - La plataforma est√° funcionando correctamente")
    else:
        print("\n‚ùå EVALUACI√ìN FALLIDA - Hay problemas que necesitan atenci√≥n")
